{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f01c1e6",
   "metadata": {},
   "source": [
    "# Step 4: Model Building\n",
    "\n",
    "Now that we have processed features (`X.csv`) and target (`y.csv`), we can train and evaluate machine learning models to predict **Laptop Prices**.  \n",
    "\n",
    "### Goals of this notebook:\n",
    "1. Load processed features and target.  \n",
    "2. Split data into training and test sets.  \n",
    "3. Train baseline regression models.  \n",
    "4. Evaluate models using metrics (R², RMSE).  \n",
    "5. Save the best-performing model for deployment.  \n",
    "\n",
    "\n",
    "Author: Joseph prince \n",
    "Registration Number: 22/EG/CO/1774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e48a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4b4a4",
   "metadata": {},
   "source": [
    "## Step 2: Load Processed Data\n",
    "We load the features (`X.csv`) and target (`y.csv`) from Step 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "952ada85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop_ID                  int64\n",
      "Inches                   float64\n",
      "Memory                    object\n",
      "Ram_GB                     int64\n",
      "Company_std               object\n",
      "OpSys_std                 object\n",
      "Weight_kg                float64\n",
      "Screen_W                   int64\n",
      "Screen_H                   int64\n",
      "PPI                      float64\n",
      "Company_Apple               bool\n",
      "Company_Asus                bool\n",
      "Company_Chuwi               bool\n",
      "Company_Dell                bool\n",
      "Company_Fujitsu             bool\n",
      "Company_Google              bool\n",
      "Company_HP                  bool\n",
      "Company_Huawei              bool\n",
      "Company_LG                  bool\n",
      "Company_Lenovo              bool\n",
      "Company_MSI                 bool\n",
      "Company_Mediacom            bool\n",
      "Company_Microsoft           bool\n",
      "Company_Razer               bool\n",
      "Company_Samsung             bool\n",
      "Company_Toshiba             bool\n",
      "Company_Vero                bool\n",
      "Company_Xiaomi              bool\n",
      "TypeName_Gaming             bool\n",
      "TypeName_Netbook            bool\n",
      "TypeName_Notebook           bool\n",
      "TypeName_Ultrabook          bool\n",
      "TypeName_Workstation        bool\n",
      "Cpu_Brand_Intel             bool\n",
      "Cpu_Brand_Other             bool\n",
      "Gpu_Brand_Intel             bool\n",
      "Gpu_Brand_Nvidia            bool\n",
      "Gpu_Brand_Other             bool\n",
      "OS_Simplified_MacOS         bool\n",
      "OS_Simplified_Other         bool\n",
      "OS_Simplified_Windows       bool\n",
      "dtype: object\n",
      "Features shape (X): (1303, 41)\n",
      "Target shape (y): (1303,)\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Step 0: Load fully processed data\n",
    "# ==============================\n",
    "X = pd.read_csv(\"../data/processed/X.csv\")\n",
    "y = pd.read_csv(\"../data/processed/y.csv\")[\"Price\"]\n",
    "\n",
    "# Quick check\n",
    "print(X.dtypes)\n",
    "\n",
    "# Quick check: print shapes to confirm correct loading\n",
    "print(\"Features shape (X):\", X.shape)\n",
    "print(\"Target shape (y):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b58339",
   "metadata": {},
   "source": [
    "## Step 3: Train-Test Split\n",
    "We will split the dataset into **75% training** and **25% testing**. Ranson state: 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57905061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (977, 41) (977,)\n",
      "Testing set size: (326, 41) (326,)\n"
     ]
    }
   ],
   "source": [
    "# Keep raw features (Company_std, OpSys_std, Ram_GB, Weight_kg, Screen_W, Screen_H, etc.)\n",
    "# Do NOT apply get_dummies here, the pipeline will handle encoding\n",
    "\n",
    "\n",
    "# Split into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=24\n",
    ")\n",
    "\n",
    "# Print sizes of splits\n",
    "print(\"Training set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a9143",
   "metadata": {},
   "source": [
    "## Step 4: Baseline Model - Linear Regression\n",
    "We start simple with a **Linear Regression** model to establish a baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ed2dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "R² Score: 0.7645748365980322\n",
      "RMSE: 339.52295830518096\n"
     ]
    }
   ],
   "source": [
    "# --- Convert Memory to numeric Storage_GB ---\n",
    "def convert_memory(mem_str):\n",
    "    total = 0\n",
    "    for part in mem_str.split('+'):\n",
    "        part = part.strip()\n",
    "        match = re.search(r'[\\d.]+', part)\n",
    "        if match:\n",
    "            num = float(match.group())\n",
    "            if 'TB' in part:\n",
    "                total += num * 1024\n",
    "            else:\n",
    "                total += num\n",
    "    return total\n",
    "\n",
    "X_train['Storage_GB'] = X_train['Memory'].apply(convert_memory)\n",
    "X_test['Storage_GB'] = X_test['Memory'].apply(convert_memory)\n",
    "\n",
    "# Drop unnecessary columns safely\n",
    "X_train = X_train.drop(columns=[\"Memory\", \"laptop_ID\", \"Company_std\", \"OpSys_std\"], errors=\"ignore\")\n",
    "X_test = X_test.drop(columns=[\"Memory\", \"laptop_ID\", \"Company_std\", \"OpSys_std\"], errors=\"ignore\")\n",
    "\n",
    "\n",
    "# --- Define numeric columns to scale ---\n",
    "numerical_cols = [\"Ram_GB\", \"Weight_kg\", \"Screen_W\", \"Screen_H\", \"PPI\", \"Inches\", \"Storage_GB\"]\n",
    "\n",
    "# Preprocessor: scale numeric, leave all boolean columns as-is\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# Build pipeline\n",
    "linreg_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", LinearRegression())\n",
    "])\n",
    "\n",
    "# Fit model\n",
    "linreg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lr = linreg_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "print(\"Linear Regression Results:\")\n",
    "print(\"R² Score:\", r2_lr)\n",
    "print(\"RMSE:\", rmse_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81718c68",
   "metadata": {},
   "source": [
    "## Step 5: Regularized Models (Ridge & Lasso)\n",
    "To handle multicollinearity and feature selection, we try **Ridge** and **Lasso** regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cda02026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression → R²: 0.7602772222379485 RMSE: 342.6078872523094\n",
      "Lasso Regression → R²: 0.7644946044191632 RMSE: 339.5808075720957\n"
     ]
    }
   ],
   "source": [
    "# --- Define numeric columns ---\n",
    "numerical_cols = [\"Ram_GB\", \"Weight_kg\", \"Screen_W\", \"Screen_H\", \"PPI\", \"Inches\", \"Storage_GB\"]\n",
    "\n",
    "# Preprocessor: scale numeric, leave all boolean columns as-is\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), numerical_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# --- Ridge pipeline ---\n",
    "ridge_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", Ridge(alpha=1.0))\n",
    "])\n",
    "\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_pipeline.predict(X_test)\n",
    "\n",
    "# --- Lasso pipeline ---\n",
    "lasso_pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", Lasso(alpha=0.01, max_iter=10000))\n",
    "])\n",
    "\n",
    "lasso_pipeline.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso_pipeline.predict(X_test)\n",
    "\n",
    "# --- Results ---\n",
    "print(\"Ridge Regression → R²:\", r2_score(y_test, y_pred_ridge),\n",
    "      \"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_ridge)))\n",
    "\n",
    "print(\"Lasso Regression → R²:\", r2_score(y_test, y_pred_lasso),\n",
    "      \"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lasso)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9edc2b5",
   "metadata": {},
   "source": [
    "## Step 6: Ensemble Model (Random Forest)\n",
    "Tree-based models often perform better on tabular datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfb11752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results → R²: 0.8443008408282981 RMSE: 276.1123546949489\n"
     ]
    }
   ],
   "source": [
    "# Detect categorical columns that still exist in X_train\n",
    "categorical_cols = [col for col in X_train.select_dtypes(include=['object']).columns if col in X_train.columns]\n",
    "\n",
    "# Initialize OrdinalEncoder\n",
    "encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "\n",
    "# Encode both train and test (only if there are categorical columns)\n",
    "if categorical_cols:\n",
    "    X_train[categorical_cols] = encoder.fit_transform(X_train[categorical_cols].astype(str))\n",
    "    X_test[categorical_cols] = encoder.transform(X_test[categorical_cols].astype(str))\n",
    "\n",
    "# Make sure all features are numeric\n",
    "X_train = X_train.apply(pd.to_numeric, errors='coerce').fillna(-1)\n",
    "X_test  = X_test.apply(pd.to_numeric, errors='coerce').fillna(-1)\n",
    "\n",
    "# Initialize Random Forest with 200 trees\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Random Forest Results → R²:\", r2_score(y_test, y_pred_rf), \n",
    "      \"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e95b1a",
   "metadata": {},
   "source": [
    "## Step 7: Cross-Validation\n",
    "We use **cross-validation** on the training set for more robust evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638c6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV R² scores: [0.81625161 0.66809524 0.80377929 0.79687999 0.77311206]\n",
      "Mean CV R²: 0.7716236378289423\n",
      "['num__Inches' 'num__Ram_GB' 'num__Weight_kg' 'num__Screen_W'\n",
      " 'num__Screen_H' 'num__PPI' 'num__Storage_GB']\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation on Random Forest\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"r2\")\n",
    "\n",
    "print(\"Random Forest CV R² scores:\", cv_scores)\n",
    "print(\"Mean CV R²:\", np.mean(cv_scores))\n",
    "\n",
    "print(pipeline.named_steps[\"preprocessor\"].get_feature_names_out()) # get the names the input date will have\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9633a",
   "metadata": {},
   "source": [
    "## Step 8: Save Best Model\n",
    "We will save the **Random Forest model** (best performer) to disk.  \n",
    "It can later be loaded in **Step 5 (Model Evaluation/Deployment)**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0019d59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline saved to models/laptop_price_pipeline.pkl\n"
     ]
    }
   ],
   "source": [
    "# Detect categorical columns that exist in X_train\n",
    "categorical_cols = [col for col in X_train.select_dtypes(include=['object']).columns if col in X_train.columns]\n",
    "\n",
    "# Detect numerical columns that exist in X_train\n",
    "numerical_cols = [col for col in X_train.select_dtypes(include=['int64', 'float64']).columns if col in X_train.columns]\n",
    "\n",
    "# Preprocessor: OneHotEncode categorical, passthrough numerical\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_cols),\n",
    "        (\"num\", \"passthrough\", numerical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Build pipeline (preprocessor + RandomForest)\n",
    "pipeline = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"model\", RandomForestRegressor(n_estimators=200, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit pipeline on training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Save pipeline\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "joblib.dump(pipeline, \"models/laptop_price_pipeline.pkl\")\n",
    "\n",
    "print(\"Pipeline saved to models/laptop_price_pipeline.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
