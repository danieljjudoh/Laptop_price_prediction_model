{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f01c1e6",
   "metadata": {},
   "source": [
    "# Step 4: Model Building\n",
    "\n",
    "Now that we have processed features (`X.csv`) and target (`y.csv`), we can train and evaluate machine learning models to predict **Laptop Prices**.  \n",
    "\n",
    "### Goals of this notebook:\n",
    "1. Load processed features and target.  \n",
    "2. Split data into training and test sets.  \n",
    "3. Train baseline regression models.  \n",
    "4. Evaluate models using metrics (R², RMSE).  \n",
    "5. Save the best-performing model for deployment.  \n",
    "\n",
    "\n",
    "Author: Joseph prince \n",
    "Registration Number: 22/EG/CO/1774"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e48a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af4b4a4",
   "metadata": {},
   "source": [
    "## Step 2: Load Processed Data\n",
    "We load the features (`X.csv`) and target (`y.csv`) from Step 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "952ada85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "laptop_ID                  int64\n",
      "Inches                   float64\n",
      "Memory                    object\n",
      "SSD_Flag                   int64\n",
      "HDD_Flag                   int64\n",
      "Storage_GB               float64\n",
      "Ram_GB                     int64\n",
      "Company_std               object\n",
      "OpSys_std                 object\n",
      "Weight_kg                float64\n",
      "Screen_W                   int64\n",
      "Screen_H                   int64\n",
      "PPI                      float64\n",
      "Company_Apple               bool\n",
      "Company_Asus                bool\n",
      "Company_Chuwi               bool\n",
      "Company_Dell                bool\n",
      "Company_Fujitsu             bool\n",
      "Company_Google              bool\n",
      "Company_HP                  bool\n",
      "Company_Huawei              bool\n",
      "Company_LG                  bool\n",
      "Company_Lenovo              bool\n",
      "Company_MSI                 bool\n",
      "Company_Mediacom            bool\n",
      "Company_Microsoft           bool\n",
      "Company_Razer               bool\n",
      "Company_Samsung             bool\n",
      "Company_Toshiba             bool\n",
      "Company_Vero                bool\n",
      "Company_Xiaomi              bool\n",
      "TypeName_Gaming             bool\n",
      "TypeName_Netbook            bool\n",
      "TypeName_Notebook           bool\n",
      "TypeName_Ultrabook          bool\n",
      "TypeName_Workstation        bool\n",
      "Cpu_Brand_Intel             bool\n",
      "Cpu_Brand_Other             bool\n",
      "Gpu_Brand_Intel             bool\n",
      "Gpu_Brand_Nvidia            bool\n",
      "Gpu_Brand_Other             bool\n",
      "OS_Simplified_MacOS         bool\n",
      "OS_Simplified_Other         bool\n",
      "OS_Simplified_Windows       bool\n",
      "dtype: object\n",
      "Features shape (X): (1303, 44)\n",
      "Target shape (y): (1303,)\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Step 0: Load fully processed data\n",
    "# ==============================\n",
    "X = pd.read_csv(\"../data/processed/X.csv\")\n",
    "y = pd.read_csv(\"../data/processed/y.csv\")[\"Price\"]\n",
    "\n",
    "# Quick check\n",
    "print(X.dtypes)\n",
    "\n",
    "# Quick check: print shapes to confirm correct loading\n",
    "print(\"Features shape (X):\", X.shape)\n",
    "print(\"Target shape (y):\", y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b58339",
   "metadata": {},
   "source": [
    "## Step 3: Train-Test Split\n",
    "We will split the dataset into **75% training** and **25% testing**. Ranson state: 24\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57905061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (977, 94) (977,)\n",
      "Testing set size: (326, 94) (326,)\n"
     ]
    }
   ],
   "source": [
    "# Convert any remaining object-type columns to numeric (example)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "\n",
    "# Split into training (80%) and testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=24\n",
    ")\n",
    "\n",
    "# Print sizes of splits\n",
    "print(\"Training set size:\", X_train.shape, y_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729a9143",
   "metadata": {},
   "source": [
    "## Step 4: Baseline Model - Linear Regression\n",
    "We start simple with a **Linear Regression** model to establish a baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ed2dd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Results:\n",
      "R² Score: 0.8058710133903709\n",
      "RMSE: 308.3102048187436\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values in features\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Initialize Linear Regression model\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Train (fit) the model\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_lr = lin_reg.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "r2_lr = r2_score(y_test, y_pred_lr)\n",
    "rmse_lr = np.sqrt(mean_squared_error(y_test, y_pred_lr))\n",
    "\n",
    "# Print results\n",
    "print(\"Linear Regression Results:\")\n",
    "print(\"R² Score:\", r2_lr)\n",
    "print(\"RMSE:\", rmse_lr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81718c68",
   "metadata": {},
   "source": [
    "## Step 5: Regularized Models (Ridge & Lasso)\n",
    "To handle multicollinearity and feature selection, we try **Ridge** and **Lasso** regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cda02026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression → R²: 0.809222042218343 RMSE: 305.6376162056968\n",
      "Lasso Regression → R²: 0.8126399286112254 RMSE: 302.88741423820636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prince/Laptop_price_prediction_model/.venv/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.572e+07, tolerance: 4.024e+04\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression\n",
    "ridge = Ridge(alpha=1.0)  # alpha = regularization strength\n",
    "ridge.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge.predict(X_test)\n",
    "\n",
    "# Lasso Regression\n",
    "lasso = Lasso(alpha=0.01)  # small alpha keeps more features\n",
    "lasso.fit(X_train, y_train)\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "\n",
    "# Print results\n",
    "print(\"Ridge Regression → R²:\", r2_score(y_test, y_pred_ridge), \n",
    "      \"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_ridge)))\n",
    "\n",
    "print(\"Lasso Regression → R²:\", r2_score(y_test, y_pred_lasso), \n",
    "      \"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lasso)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9edc2b5",
   "metadata": {},
   "source": [
    "## Step 6: Ensemble Model (Random Forest)\n",
    "Tree-based models often perform better on tabular datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfb11752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Results → R²: 0.8567411491530649 RMSE: 264.8521102572479\n"
     ]
    }
   ],
   "source": [
    "# Initialize Random Forest with 200 trees\n",
    "rf = RandomForestRegressor(n_estimators=200, random_state=42)\n",
    "\n",
    "# Train model\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Random Forest Results → R²:\", r2_score(y_test, y_pred_rf), \n",
    "      \"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_rf)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e95b1a",
   "metadata": {},
   "source": [
    "## Step 7: Cross-Validation\n",
    "We use **cross-validation** on the training set for more robust evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c638c6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest CV R² scores: [0.82229354 0.72268022 0.80167945 0.79692926 0.77910479]\n",
      "Mean CV R²: 0.7845374504489964\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation on Random Forest\n",
    "cv_scores = cross_val_score(rf, X_train, y_train, cv=5, scoring=\"r2\")\n",
    "\n",
    "print(\"Random Forest CV R² scores:\", cv_scores)\n",
    "print(\"Mean CV R²:\", np.mean(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf9633a",
   "metadata": {},
   "source": [
    "## Step 8: Save Best Model\n",
    "We will save the **Random Forest model** (best performer) to disk.  \n",
    "It can later be loaded in **Step 5 (Model Evaluation/Deployment)**.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0019d59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved to ../models/random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "\n",
    "# Now save the model\n",
    "joblib.dump(rf, \"../models/random_forest_model.pkl\")\n",
    "\n",
    "print(\"✅ Model saved to ../models/random_forest_model.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
